{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
   "metadata": {
    "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch._dynamo\n",
    "import torch._inductor\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
   "metadata": {
    "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_data_loader(data_dir, batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    train_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    valid_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "  \n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return (train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d745f184-7704-4850-9f57-4268cf20102e",
   "metadata": {
    "id": "d745f184-7704-4850-9f57-4268cf20102e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, valid_loader, num_epochs, criterion, optimizer, device):\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (images, labels) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print ('Step [{}/{}], Loss: {:.4f}'.format(step+1, total_steps, loss.item()))\n",
    "               \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
   "metadata": {
    "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "    print('Accuracy of the network on the {} validation images: {:.2f} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
   "metadata": {
    "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d_gHdGv84ocR",
   "metadata": {
    "id": "d_gHdGv84ocR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7, 512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0f9320-c37d-4d02-9bb2-96bbd7537175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TORCH_COMPILE_DEBUG'] = \"1\"\n",
    "torch._dynamo.config.log_level = logging.DEBUG\n",
    "torch._dynamo.config.verbose = True\n",
    "#torch._dynamo.config.log_level = logging.INFO\n",
    "torch._dynamo.config.output_code = True\n",
    "#torch._dynamo.config.cache_size_limit = 1\n",
    "#torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
   "metadata": {
    "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General parameters\n",
    "data_dir = '/tmp'\n",
    "num_classes = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "# Hyperparameters\n",
    "max_lr = 0.00001\n",
    "weight_decay = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "# FashionMNIST dataset \n",
    "train_loader, valid_loader, test_loader = build_data_loader(data_dir=data_dir, batch_size=batch_size)\n",
    "\n",
    "# Models\n",
    "torch._dynamo.reset()\n",
    "eager_model = CNN().to(device)\n",
    "graph_model = torch.compile(CNN().to(device), backend=\"inductor\", fullgraph=True)\n",
    "\n",
    "# Model selection\n",
    "model = graph_model\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optimizer(model.parameters(), max_lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
    "outputId": "4e39020b-7a35-4bf0-e2c4-d862cb3257f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-31 08:10:23,781] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:23,782] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:23,783] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:23,783] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:23,783] torch._dynamo.eval_frame: [DEBUG] skipping enable_dynamic /opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-31 08:10:23,786] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-05-31 08:10:23,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:19\n",
      "[2023-05-31 08:10:23,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:23,787] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,788] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:23,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:23,798] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:20\n",
      "[2023-05-31 08:10:23,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:23,799] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer2 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,800] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:23,806] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:23,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:21\n",
      "[2023-05-31 08:10:23,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []\n",
      "[2023-05-31 08:10:23,807] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR reshape [TensorVariable()]\n",
      "[2023-05-31 08:10:23,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2023-05-31 08:10:23,808] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [GetAttrVariable(TensorVariable(), reshape), TensorVariable()]\n",
      "[2023-05-31 08:10:23,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-31 08:10:23,809] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:23,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:23,810] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:23,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:23,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:22\n",
      "[2023-05-31 08:10:23,812] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:23,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,813] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:23,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:23,819] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:23\n",
      "[2023-05-31 08:10:23,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:23,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc2 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,820] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:23,821] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:23,826] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:23,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:24\n",
      "[2023-05-31 08:10:23,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []\n",
      "[2023-05-31 08:10:23,827] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-31 08:10:23,827] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-05-31 08:10:23,828] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-05-31 08:10:23,828] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1878944/3432332073.py, line 24 in forward>])\n",
      "[2023-05-31 08:10:23,830] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-05-31 08:10:24,779] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "[2023-05-31 08:10:30,580] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_xmmw/id/cidhz5eultcsac2rwjbx62kocr4j2tfvvm4wd4il7y7x766of72l.py\n",
      "[2023-05-31 08:10:30,615] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "[2023-05-31 08:10:30,615] torch._inductor.debug: [WARNING] model__0_forward_1 debug trace: /u/xmmw/book/Accelerate-Model-Training-with-PyTorch-2.0/chapters/ch3/torch_compile_debug/run_2023_05_31_08_10_23_579482-pid_1878944/aot_torchinductor/model__0_forward_1.0\n",
      "[2023-05-31 08:10:30,626] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-05-31 08:10:30,668] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_0 <eval_with_key>.5 opcode       name           target         args                     kwargs\n",
      "-----------  -------------  -------------  -----------------------  --------\n",
      "placeholder  x              x              ()                       {}\n",
      "call_module  self_layer1_0  self_layer1_0  (x,)                     {}\n",
      "call_module  self_layer1_1  self_layer1_1  (self_layer1_0,)         {}\n",
      "call_module  self_layer1_2  self_layer1_2  (self_layer1_1,)         {}\n",
      "call_module  self_layer2_0  self_layer2_0  (self_layer1_2,)         {}\n",
      "call_module  self_layer2_1  self_layer2_1  (self_layer2_0,)         {}\n",
      "call_module  self_layer2_2  self_layer2_2  (self_layer2_1,)         {}\n",
      "call_method  reshape        reshape        (self_layer2_2, 64, -1)  {}\n",
      "call_module  self_fc1       self_fc1       (reshape,)               {}\n",
      "call_module  self_fc2       self_fc2       (self_fc1,)              {}\n",
      "output       output         output         ((self_fc2,),)           {}\n",
      "\n",
      "[2023-05-31 08:10:30,668] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE forward /tmp/ipykernel_1878944/3432332073.py line 18 \n",
      " 19           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (layer1)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               2 (out)\n",
      "\n",
      " 20          10 LOAD_FAST                0 (self)\n",
      "             12 LOAD_METHOD              1 (layer2)\n",
      "             14 LOAD_FAST                2 (out)\n",
      "             16 CALL_METHOD              1\n",
      "             18 STORE_FAST               2 (out)\n",
      "\n",
      " 21          20 LOAD_FAST                2 (out)\n",
      "             22 LOAD_METHOD              2 (reshape)\n",
      "             24 LOAD_FAST                2 (out)\n",
      "             26 LOAD_METHOD              3 (size)\n",
      "             28 LOAD_CONST               1 (0)\n",
      "             30 CALL_METHOD              1\n",
      "             32 LOAD_CONST               2 (-1)\n",
      "             34 CALL_METHOD              2\n",
      "             36 STORE_FAST               2 (out)\n",
      "\n",
      " 22          38 LOAD_FAST                0 (self)\n",
      "             40 LOAD_METHOD              4 (fc1)\n",
      "             42 LOAD_FAST                2 (out)\n",
      "             44 CALL_METHOD              1\n",
      "             46 STORE_FAST               2 (out)\n",
      "\n",
      " 23          48 LOAD_FAST                0 (self)\n",
      "             50 LOAD_METHOD              5 (fc2)\n",
      "             52 LOAD_FAST                2 (out)\n",
      "             54 CALL_METHOD              1\n",
      "             56 STORE_FAST               2 (out)\n",
      "\n",
      " 24          58 LOAD_FAST                2 (out)\n",
      "             60 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-05-31 08:10:30,669] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE forward /tmp/ipykernel_1878944/3432332073.py line 18 \n",
      " 18           0 LOAD_GLOBAL              6 (__compiled_fn_0)\n",
      "              2 LOAD_FAST                1 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-05-31 08:10:30,766] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x14c52b936ac0; to 'Tensor' at 0x14c52b938900>\n",
      "                'guarded_class': <weakref at 0x14c56ac5efc0; to 'torch._C._TensorMeta' at 0x5236e10 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 22838577793680)'],\n",
      "                'obj_weakref': <weakref at 0x14c5beef36f0; to 'CNN' at 0x14c585510a90>\n",
      "                'guarded_class': <weakref at 0x14c585518810; to 'type' at 0x6d168e0 (CNN)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.fc1' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.fc2' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[0]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[1]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[2]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[0]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[1]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[2]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-05-31 08:10:30,766] torch._dynamo.eval_frame: [DEBUG] skipping _fn /opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-31 08:10:30,767] torch._dynamo.eval_frame: [DEBUG] skipping nothing /opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-05-31 08:10:30,774] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:30,775] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /opt/conda/lib/python3.10/contextlib.py\n",
      "[2023-05-31 08:10:30,803] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 0\n",
      "[2023-05-31 08:10:31,558] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_xmmw/yv/cyvt2tiawzbc6txvn4544vji3unssbdbjnk5i74okw6kfckub5vw.py\n",
      "[2023-05-31 08:10:31,578] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 0\n",
      "[2023-05-31 08:10:31,579] torch._inductor.debug: [WARNING] model__0_backward_2 debug trace: /u/xmmw/book/Accelerate-Model-Training-with-PyTorch-2.0/chapters/ch3/torch_compile_debug/run_2023_05_31_08_10_23_579482-pid_1878944/aot_torchinductor/model__0_backward_2.1\n",
      "[2023-05-31 08:10:41,429] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-05-31 08:10:41,437] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:19\n",
      "[2023-05-31 08:10:41,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:41,438] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,441] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:41,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:41,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:20\n",
      "[2023-05-31 08:10:41,454] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:41,455] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer2 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,456] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:41,461] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:41,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:21\n",
      "[2023-05-31 08:10:41,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []\n",
      "[2023-05-31 08:10:41,462] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR reshape [TensorVariable()]\n",
      "[2023-05-31 08:10:41,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2023-05-31 08:10:41,463] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [GetAttrVariable(TensorVariable(), reshape), TensorVariable()]\n",
      "[2023-05-31 08:10:41,464] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-31 08:10:41,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:41,465] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:41,466] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:41,467] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:41,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:22\n",
      "[2023-05-31 08:10:41,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:41,468] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,469] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:41,475] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:41,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:23\n",
      "[2023-05-31 08:10:41,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:41,476] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc2 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:41,477] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:41,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:41,482] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:24\n",
      "[2023-05-31 08:10:41,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []\n",
      "[2023-05-31 08:10:41,483] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-05-31 08:10:41,483] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-05-31 08:10:41,484] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-05-31 08:10:41,484] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1878944/3432332073.py, line 24 in forward>])\n",
      "[2023-05-31 08:10:41,487] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-05-31 08:10:41,663] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1\n",
      "[2023-05-31 08:10:43,141] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_xmmw/uf/cuflwif2vciu5p75c4jphace37wouu6ewifxvhw5zxljsqrosabf.py\n",
      "[2023-05-31 08:10:43,161] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1\n",
      "[2023-05-31 08:10:43,162] torch._inductor.debug: [WARNING] model__1_forward_4 debug trace: /u/xmmw/book/Accelerate-Model-Training-with-PyTorch-2.0/chapters/ch3/torch_compile_debug/run_2023_05_31_08_10_23_579482-pid_1878944/aot_torchinductor/model__1_forward_4.2\n",
      "[2023-05-31 08:10:43,173] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-05-31 08:10:43,174] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_1 <eval_with_key>.36 opcode       name           target         args                     kwargs\n",
      "-----------  -------------  -------------  -----------------------  --------\n",
      "placeholder  x              x              ()                       {}\n",
      "call_module  self_layer1_0  self_layer1_0  (x,)                     {}\n",
      "call_module  self_layer1_1  self_layer1_1  (self_layer1_0,)         {}\n",
      "call_module  self_layer1_2  self_layer1_2  (self_layer1_1,)         {}\n",
      "call_module  self_layer2_0  self_layer2_0  (self_layer1_2,)         {}\n",
      "call_module  self_layer2_1  self_layer2_1  (self_layer2_0,)         {}\n",
      "call_module  self_layer2_2  self_layer2_2  (self_layer2_1,)         {}\n",
      "call_method  reshape        reshape        (self_layer2_2, 48, -1)  {}\n",
      "call_module  self_fc1       self_fc1       (reshape,)               {}\n",
      "call_module  self_fc2       self_fc2       (self_fc1,)              {}\n",
      "output       output         output         ((self_fc2,),)           {}\n",
      "\n",
      "[2023-05-31 08:10:43,174] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE forward /tmp/ipykernel_1878944/3432332073.py line 18 \n",
      " 19           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_METHOD              0 (layer1)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 CALL_METHOD              1\n",
      "              8 STORE_FAST               2 (out)\n",
      "\n",
      " 20          10 LOAD_FAST                0 (self)\n",
      "             12 LOAD_METHOD              1 (layer2)\n",
      "             14 LOAD_FAST                2 (out)\n",
      "             16 CALL_METHOD              1\n",
      "             18 STORE_FAST               2 (out)\n",
      "\n",
      " 21          20 LOAD_FAST                2 (out)\n",
      "             22 LOAD_METHOD              2 (reshape)\n",
      "             24 LOAD_FAST                2 (out)\n",
      "             26 LOAD_METHOD              3 (size)\n",
      "             28 LOAD_CONST               1 (0)\n",
      "             30 CALL_METHOD              1\n",
      "             32 LOAD_CONST               2 (-1)\n",
      "             34 CALL_METHOD              2\n",
      "             36 STORE_FAST               2 (out)\n",
      "\n",
      " 22          38 LOAD_FAST                0 (self)\n",
      "             40 LOAD_METHOD              4 (fc1)\n",
      "             42 LOAD_FAST                2 (out)\n",
      "             44 CALL_METHOD              1\n",
      "             46 STORE_FAST               2 (out)\n",
      "\n",
      " 23          48 LOAD_FAST                0 (self)\n",
      "             50 LOAD_METHOD              5 (fc2)\n",
      "             52 LOAD_FAST                2 (out)\n",
      "             54 CALL_METHOD              1\n",
      "             56 STORE_FAST               2 (out)\n",
      "\n",
      " 24          58 LOAD_FAST                2 (out)\n",
      "             60 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-05-31 08:10:43,175] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE forward /tmp/ipykernel_1878944/3432332073.py line 18 \n",
      " 18           0 LOAD_GLOBAL              6 (__compiled_fn_1)\n",
      "              2 LOAD_FAST                1 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-05-31 08:10:43,176] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x14c5854ee1b0; to 'Tensor' at 0x14c5854eed40>\n",
      "                'guarded_class': <weakref at 0x14c56ac5efc0; to 'torch._C._TensorMeta' at 0x5236e10 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 22838577793680)'],\n",
      "                'obj_weakref': <weakref at 0x14c5beef36f0; to 'CNN' at 0x14c585510a90>\n",
      "                'guarded_class': <weakref at 0x14c585518810; to 'type' at 0x6d168e0 (CNN)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.fc1' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.fc2' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[0]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[1]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer1[2]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[0]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[1]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.layer2[2]' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-05-31 08:10:43,205] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 1\n",
      "[2023-05-31 08:10:43,931] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_xmmw/xp/cxpb37ttsj5cyvritbucz66xea6i2upinno5u5yqg6k5pncm5j4e.py\n",
      "[2023-05-31 08:10:43,979] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 1\n",
      "[2023-05-31 08:10:43,979] torch._inductor.debug: [WARNING] model__1_backward_5 debug trace: /u/xmmw/book/Accelerate-Model-Training-with-PyTorch-2.0/chapters/ch3/torch_compile_debug/run_2023_05_31_08_10_23_579482-pid_1878944/aot_torchinductor/model__1_backward_5.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.7764\n",
      "Training time: 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-31 08:10:44,897] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-05-31 08:10:44,898] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:19\n",
      "[2023-05-31 08:10:44,899] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:44,899] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,900] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:44,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:44,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:20\n",
      "[2023-05-31 08:10:44,906] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:44,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer2 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,907] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,908] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:44,912] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:44,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:21\n",
      "[2023-05-31 08:10:44,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []\n",
      "[2023-05-31 08:10:44,913] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR reshape [TensorVariable()]\n",
      "[2023-05-31 08:10:44,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2023-05-31 08:10:44,914] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR size [GetAttrVariable(TensorVariable(), reshape), TensorVariable()]\n",
      "[2023-05-31 08:10:44,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size)]\n",
      "[2023-05-31 08:10:44,915] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [GetAttrVariable(TensorVariable(), reshape), GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:44,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:44,916] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-05-31 08:10:44,917] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:44,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:22\n",
      "[2023-05-31 08:10:44,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-05-31 08:10:44,918] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc1 [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,919] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]\n",
      "[2023-05-31 08:10:44,920] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-05-31 08:10:44,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]\n",
      "[2023-05-31 08:10:44,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_1878944/3432332073.py:23\n",
      "[2023-05-31 08:10:44,924] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(model, train_loader, valid_loader, num_epochs, criterion, optimizer, device)\n",
    "end = time.time()\n",
    "print('Training time: {} seconds'.format(int(end - start)))\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
   "metadata": {
    "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "prof = profile(activities=activities, with_stack=True, record_shapes=True, on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/cnn/'))\n",
    "        \n",
    "input_sample, _ = next(iter(train_loader))\n",
    "\n",
    "prof.start()\n",
    "model(input_sample.to(device))\n",
    "prof.stop()\n",
    "\n",
    "#prof.export_chrome_trace(\"./cnn_trace.json\")\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614736-498a-423a-a757-630299962db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
